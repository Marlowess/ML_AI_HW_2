{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Machine Learning and Artificial Intelligence</h1>\n",
    "<h2 align=\"center\">Stefano Brilli s249914 - Homework 2</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Analysis definition\n",
    "In this homework we will use a tool for classification, called <b>Support Vector Machine</b>, in order to classify flowers according to their features. The dataset is presented in one of the next chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Definition of hyperplane\n",
    "In a p-dimensional space, a hyperplane is a flat affine subspace of dimension p-1 (the word affine indicates that the subspace need not pass through the origin).\n",
    "In three dimensions, a hyperplane is a flat two-dimensional subspace, that is a plane.\n",
    "In two dimensions it's a line. The mathematical definition of a hyperplane is quite simple. In two dimensione, a hyperplane is defined by the equation {{r'\\beta_{0}+\\beta_{1}X_{1}-X_{2}=0'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\beta_{0}+\\beta_{1}X_{1}-X_{2}=0$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Math(r'\\beta_{0}+\\beta_{1}X_{1}-X_{2}=0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 SVM briefly explanation\n",
    "SVM is a supervised algorithm used for classifying data belonging to two or more classes. The objective is to find the hyperplane that separates well data.\n",
    "It means that for each point we want to assign it a label according to the side it belongs to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Large Margin Separation\n",
    "If our data can be perfectly separated using a hyperplane, then there exists an infinte number of such hyperplanes.\n",
    "We have to decide which of these hyperplanes we want to use to separate data.\n",
    "A natural choice is the <i>large margin separation</i> (also called <i>maximal margin separation</i>), which is the separating hyperplane so that the distance between two point groups is as large as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Soft Margin Separation\n",
    "In order to get a greater robustness to individual observations and obtain a better classification of most of the training observations, we can fit the model by using a soft margin classifier.\n",
    "The idea here is: rather than seeking the largest possible margin so that every observation is not only on the correct side of the hyperplane but also on the correct side of the margin, we instead allow some observations to be on the incorrect side of the margin, or even the incorrect side of the hyperplane. The margin is called soft because it can be violated by some of the training observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 The dataset\n",
    "Our analysis will be performed on the <i>iris</i> data, available at https://archive.ics.uci.edu/ml/datasets/iris or by importing the data sets library of sklearn.\n",
    "The data set contains 150 observations belonging to 3 classes, where each class is referred to a type of iris plant.\n",
    "For simplicity we will use just two features of the dataset: <i>sepal length in cm</i> and <i>sepal width in cm</i>.\n",
    "<table style=\"border: 1px solid black;\">\n",
    "    <tr>\n",
    "        <th style=\"border: 1px solid black\">Class 1</th>\n",
    "        <th style=\"border: 1px solid black;\">Class 2</th>\n",
    "        <th style=\"border: 1px solid black;\">Class 3</th>\n",
    "        <th style=\"border: 1px solid black;\">Feature 1</th>\n",
    "        <th style=\"border: 1px solid black;\">Feature 2</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 1px solid black;\">Iris-setosa</th>\n",
    "        <td style=\"border: 1px solid black;\">Iris-versicolor</th>\n",
    "        <td style=\"border: 1px solid black;\">Iris-virginica</th>\n",
    "        <td style=\"border: 1px solid black;\">sepal length in cm </th>\n",
    "        <td style=\"border: 1px solid black;\">sepal width in cm </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 1px solid black;\">[0]</th>\n",
    "        <td style=\"border: 1px solid black;\">[1]</th>\n",
    "        <td style=\"border: 1px solid black;\">[2]</th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Linear and non-linear SVM\n",
    "According to the <i>Convergence Theorem</i> it's always possible to find a hyperplane that separates data that are linearly separable (http://www.cems.uvm.edu/~rsnapp/teaching/cs295ml/notes/perceptron.pdf).\n",
    "Many times this condition isn't satisfied, so it's necessary to find another separation. In this homework I will use both linear and non-linear kernel to find a hyperplane. I will use the following kernels for classifying data:<br>\n",
    "    • <b>Linear kernel</b>: I've to find the best C hyperparameter<br>\n",
    "    • <b>RBF</b>: I've to find C and λ hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Used tools\n",
    "As for the previous homework, we will use the Python language and sklearn libraries to complete the analysis  (http://scikit-learn.org/stable/documentation.html) and matplotlib for plotting data (https://matplotlib.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets, svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from tabulate import tabulate\n",
    "from IPython.display import Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function load the iris dataset in memory and gets just the first two dimensions\n",
    "def loadData():\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data[:, :2]\n",
    "    y = iris.target\n",
    "    return X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
